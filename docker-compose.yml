version: '2'

networks:
    datapipeline:
        driver: bridge
        ipam:
            driver: default
            config:
                - subnet: "172.18.0.0/16"

services:  
  zookeeper:
    image: 'bitnami/zookeeper:3.9.1'
    container_name: zookeeper
    hostname: zookeeper
    ports:
      - '2181:2181'
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes
    networks:
      datapipeline:
        ipv4_address: 172.18.0.3
  
  kafka:
    image: 'bitnami/kafka:3.4.1'
    container_name: kafka
    hostname: kafka
    ports:
      - '9092:9092'
    environment:
      - KAFKA_BROKER_ID=1
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
      - ALLOW_PLAINTEXT_LISTENER=yes
      - TOPIC_NAME=Sales
    depends_on:
      zookeeper:
        condition: service_started
    volumes:
      - ./kafka/kafka-setup.sh:/kafka-setup.sh
    networks:
      datapipeline:
        ipv4_address: 172.18.0.4

  cassandra:
    image: cassandra:4
    container_name: cassandra
    hostname: cassandra
    ports:
      - '9042:9042'
    volumes:
      - ./cassandra/cassandra-init.sh:/cassandra-init.sh
    networks:
      datapipeline:
        ipv4_address: 172.18.0.5

  spark-consumer:
    build:
      context: ./spark
      dockerfile: dockerfile
    container_name: spark-consumer
    restart: always
    networks:
      datapipeline:
        ipv4_address: 172.18.0.6

  api-producer:
    build:
      context: ./api-producer
      dockerfile: dockerfile
    container_name: api-producer
    restart: always
    ports:
      - '8081:8080'
    networks:
      datapipeline:
        ipv4_address: 172.18.0.7

  redash:
    image: saadeddine123/redash:1.0
    container_name: redash
    depends_on:
      cassandra:
        condition: service_started
    ports:
      - '5000:5000'
    networks:
      datapipeline:
        ipv4_address: 172.18.0.8
    restart: always
